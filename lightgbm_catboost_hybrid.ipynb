{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM and Catboost hybrid\n",
    "\n",
    "A simple walkthrough of some essential steps in creating first set of predictions for a competition. There's normally more work involved in each of these steps (filling NaNs, feature engineering, parameter tuning, validation  ensembling) before going for next step, but here we just go through each step briefly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing values per column\n",
    "train.isnull().sum(axis=0) / train.shape[0]\n",
    "\n",
    "# input missing values\n",
    "train['siteid'].fillna(-999, inplace=True)\n",
    "test['siteid'].fillna(-999, inplace=True)\n",
    "\n",
    "train['browserid'].fillna(\"None\", inplace=True)\n",
    "test['browserid'].fillna(\"None\", inplace=True)\n",
    "\n",
    "train['devid'].fillna(\"None\", inplace=True)\n",
    "test['devid'].fillna(\"None\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set datetime dtype to the column\n",
    "train['datetime'] = pd.to_datetime(train['datetime'])\n",
    "test['datetime'] = pd.to_datetime(test['datetime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Better way to do the above is to set `parse_dates` argument to list of datetime column names when importing csv in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datetime variable\n",
    "train['tweekday'] = train['datetime'].dt.weekday\n",
    "train['thour'] = train['datetime'].dt.hour\n",
    "train['tminute'] = train['datetime'].dt.minute\n",
    "\n",
    "test['tweekday'] = test['datetime'].dt.weekday\n",
    "test['thour'] = test['datetime'].dt.hour\n",
    "test['tminute'] = test['datetime'].dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['siteid', 'offerid', 'category', 'merchant']\n",
    "\n",
    "for x in cols:\n",
    "    train[x] = train[x].astype('object')\n",
    "    test[x] = test[x].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_use = list(set(train.columns) - set(['ID', 'datetime', 'click']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Model 1 - Catboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = range(10)\n",
    "\n",
    "models = []\n",
    "np.random.seed(42)\n",
    "for i in tqdm.tqdm_notebook(range(10)):\n",
    "    rows = np.random.choice(train.index.values, int(1e6))\n",
    "    sampled_train = train.loc[rows]\n",
    "    trainX = sampled_train[cols_to_use]\n",
    "    trainY = sampled_train['click']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(trainX, trainY, test_size=0.5)\n",
    "\n",
    "    cat_boost_params = {\n",
    "        'depth': 13 + np.random.randint(5)\n",
    "        'iterations': 50 + np.random.randint(10),\n",
    "        'learning_rate': 0.1 + (np.random.rand() * 1e-1),\n",
    "        'eval_metric': 'AUC',\n",
    "        'random_seed': np.random.randint(10 ** 10),\n",
    "        'verbose': True\n",
    "    }\n",
    "    model = CatBoostClassifier(**cat_boost_params)\n",
    "    model.fit(X_train, y_train, cat_features=cat_cols, eval_set=(X_test, y_test), use_best_model=True)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost all of the parameter values are an overkill for a baseline predictions, but these are just to remember that there are more parameters to try if we need them.\n",
    "\n",
    "In general, `learning rate` and `depth` matter the most. Consult library docs for what are default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print models[0]\n",
    "models[0].save_model('first_model', format='coreml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Model 2 - LightGBM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = cols + ['countrycode', 'browserid', 'devid']\n",
    "\n",
    "models2 = []\n",
    "np.random.seed(42)\n",
    "for i in tqdm.tqdm_notebook(range(10)):\n",
    "    for col in cat_cols:\n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(train[col].values) + list(test[col].values))\n",
    "        train[col] = lbl.transform(list(train[col].values))\n",
    "        test[col] = lbl.transform(list(test[col].values))\n",
    "\n",
    "    lgbm_cols_to_use = list(set(train.columns) - set(['ID', 'datetime', 'click']))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train[lgbm_cols_to_use], train['click'], test_size=0.5)\n",
    "    dtrain = lgb.Dataset(X_train, y_train)\n",
    "    dval = lgb.Dataset(X_test, y_test)\n",
    "\n",
    "    lightgbm_params = {\n",
    "        'seed': np.random.randint(10 ** 10),\n",
    "        'num_leaves': 384 + np.random.randint(0, 128),\n",
    "        'learning_rate': 0.05 + (np.random.rand() * 1e-2),\n",
    "        'metric': 'auc',\n",
    "        'objective': 'binary',\n",
    "        'early_stopping_round': 40,\n",
    "        'max_depth': 12 + np.random.randint(0, 10),\n",
    "        'bagging_fraction': 0.5,\n",
    "        'feature_fraction': 0.6,\n",
    "        'bagging_seed': 2017,\n",
    "        'feature_fraction_seed': 2017,\n",
    "        'verbose': 1,\n",
    "        'boosting': 'goss'\n",
    "    }\n",
    "    model = lgb.train(lightgbm_params, dtrain, num_boost_round=500, valid_sets=dval, verbose_eval=20)\n",
    "    models2.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the parameters are an overkill! Same as with catboost model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Ensemble\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for _model in tqdm.tqdm_notebook(models):\n",
    "    predictions.append(_model.predict_proba(test[cols_to_use])[:, 1])\n",
    "\n",
    "predictions = np.vstack(predictions).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = []\n",
    "\n",
    "for _model in tqdm.tqdm_notebook(models2):\n",
    "    predictions2.append(_model.predict(test[cols_to_use])[:, 1])\n",
    "\n",
    "predictions2 = np.vstack(predictions2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.hstack([predictions, predictions2]).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({'ID': test['ID'], 'click': prediction})\n",
    "sub.to_csv('prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
